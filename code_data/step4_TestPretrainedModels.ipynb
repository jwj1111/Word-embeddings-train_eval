{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2c1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从本地载入或下载模型\n",
    "def get_pretrained_vectors(model_name):\n",
    "    filepath=rf'''pretrained_models/{model_name}.kv'''\n",
    "    if os.path.exists(filepath):\n",
    "        vectors=KeyedVectors.load(filepath,mmap='r')\n",
    "    else:\n",
    "        print(f'downloading {model_name}')\n",
    "        vectors=gensim.downloader.load(model_name)\n",
    "        vectors.save(filepath)\n",
    "        print(f'{model_name} saved')\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入测试数据，与step3相同\n",
    "def test_data_prepare(filename):\n",
    "    with open(filename,'r',encoding='utf-8') as infile:\n",
    "        if 'WordSim' in filename:\n",
    "            pair_gold=[]\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if not line.startswith('Word 1'):\n",
    "                    line_elements=line.split(',')\n",
    "                    pair_gold.append(((line_elements[0].lower(),line_elements[1].lower()),float(line_elements[2])))\n",
    "            return pair_gold\n",
    "        if 'SimLex' in filename:\n",
    "            pair_gold=[]\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if not line.startswith('word1'):\n",
    "                    line_elements=line.split('\\t')\n",
    "                    pair_gold.append(((line_elements[0].lower(),line_elements[1].lower()),float(line_elements[3])))\n",
    "            return pair_gold\n",
    "        if 'Analogy' in filename:\n",
    "            sem_positives_negative=[]\n",
    "            sem_answers=[]\n",
    "            mor_positives_negative=[]\n",
    "            mor_answers=[]\n",
    "            category=None\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if line.startswith(':'):\n",
    "                    category=1 if 'gram' in line else 0\n",
    "                else:\n",
    "                    line_elements=line.split()\n",
    "                    if category==0:\n",
    "                        sem_positives_negative.append(([line_elements[2].lower(),line_elements[1].lower()],line_elements[0].lower()))\n",
    "                        sem_answers.append(line_elements[3].lower())\n",
    "                    else:\n",
    "                        mor_positives_negative.append(([line_elements[2].lower(),line_elements[1].lower()],line_elements[0].lower()))\n",
    "                        mor_answers.append(line_elements[3].lower())        \n",
    "            return sem_positives_negative,sem_answers,mor_positives_negative,mor_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eba62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试相关性能力，与step3基本相同\n",
    "def similarity_test(pair_gold,vectors_list):\n",
    "    r_values=[]\n",
    "    p_r_values=[]\n",
    "    rho_values=[]\n",
    "    p_rho_values=[]\n",
    "    test_coverage=[]\n",
    "    test_pair_num=len(pair_gold)\n",
    "    for test_vectors in vectors_list:\n",
    "        gold_sim=[]\n",
    "        pred_sim=[]\n",
    "        oov_pair_num=0\n",
    "        for pair,gold in pair_gold:\n",
    "            try:\n",
    "                pred=test_vectors.similarity(*pair)\n",
    "                gold_sim.append(gold)\n",
    "                pred_sim.append(pred)\n",
    "            except KeyError:\n",
    "                oov_pair_num+=1\n",
    "                continue\n",
    "        r,p_r=scipy.stats.pearsonr(gold_sim,pred_sim)\n",
    "        rho,p_rho=scipy.stats.spearmanr(gold_sim,pred_sim)\n",
    "        coverage=(test_pair_num-oov_pair_num)/test_pair_num\n",
    "        r_values.append(r)\n",
    "        p_r_values.append(p_r)\n",
    "        rho_values.append(rho)\n",
    "        p_rho_values.append(p_rho)\n",
    "        test_coverage.append(coverage)\n",
    "    return r_values,p_r_values,rho_values,p_rho_values,test_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#与step3基本相同\n",
    "def wordsim_test(model_info,vectors_list,test_data_path):\n",
    "    wordsim_pair_gold=test_data_prepare(test_data_path)\n",
    "    wordsim_r,wordsim_pr,wordsim_rho,wordsim_prho,wordsim_coverage=similarity_test(pair_gold=wordsim_pair_gold,vectors_list=vectors_list)\n",
    "    model_info['wordsim_r']=wordsim_r\n",
    "    model_info['wordsim_p_r']=wordsim_pr\n",
    "    model_info['wordsim_rho']=wordsim_rho\n",
    "    model_info['wordsim_prho']=wordsim_prho\n",
    "    model_info['wordsim_coverage']=wordsim_coverage\n",
    "    print('wordsim测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6042d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#与step3基本相同\n",
    "def simlex_test(model_info,vectors_list,test_data_path):\n",
    "    simlex_pair_gold=test_data_prepare(test_data_path)\n",
    "    simlex_r,simlex_pr,simlex_rho,simlex_prho,simlex_coverage=similarity_test(pair_gold=simlex_pair_gold,vectors_list=vectors_list)\n",
    "    model_info['simlex_r']=simlex_r\n",
    "    model_info['simlex_p_r']=simlex_pr\n",
    "    model_info['simlex_rho']=simlex_rho\n",
    "    model_info['simlex_prho']=simlex_prho\n",
    "    model_info['simlex_coverage']=simlex_coverage\n",
    "    print('simlex测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试类比推理能力，与step3基本相同\n",
    "def analogy_test(model_info,vectors_list,test_data_path):\n",
    "    sem_positives_negative,sem_answers,mor_positives_negative,mor_answers=test_data_prepare(test_data_path)\n",
    "    sem_num,mor_num=len(sem_positives_negative),len(mor_positives_negative)\n",
    "    all_num=sem_num+mor_num\n",
    "    sem_accuracy,mor_accuracy,all_accuracy=[],[],[]\n",
    "    sem_coverage,mor_coverage,all_coverage=[],[],[]\n",
    "    Round=0\n",
    "    for test_vectors in vectors_list:\n",
    "        accuracy_count={'sem':0,'mor':0}\n",
    "        sem_oov_pair_num=0\n",
    "        mor_oov_pair_num=0\n",
    "        for sem_pos_neg,sem_answer in tqdm(zip(sem_positives_negative,sem_answers),total=sem_num,desc='analogy_test_sem'):\n",
    "            sem_pos_pair,sem_neg=sem_pos_neg\n",
    "            try:\n",
    "                pred_semword=test_vectors.most_similar(positive=sem_pos_pair,negative=[sem_neg],topn=1)[0][0]\n",
    "                if pred_semword==sem_answer:\n",
    "                    accuracy_count['sem']+=1\n",
    "            except KeyError:\n",
    "                sem_oov_pair_num+=1\n",
    "                continue\n",
    "        for mor_pos_neg,mor_answer in tqdm(zip(mor_positives_negative,mor_answers),total=mor_num,desc='analogy_test_mor'):\n",
    "            mor_pos_pair,mor_neg=mor_pos_neg\n",
    "            try:\n",
    "                pred_morword=test_vectors.most_similar(positive=mor_pos_pair,negative=[mor_neg],topn=1)[0][0]\n",
    "                if pred_morword==mor_answer:\n",
    "                    accuracy_count['mor']+=1\n",
    "            except KeyError:\n",
    "                mor_oov_pair_num+=1\n",
    "                continue\n",
    "        sem_valid_num=sem_num-sem_oov_pair_num\n",
    "        mor_valid_num=mor_num-mor_oov_pair_num\n",
    "        all_valid_num=all_num-sem_oov_pair_num-mor_oov_pair_num\n",
    "        sem_acc=accuracy_count['sem']/sem_valid_num\n",
    "        mor_acc=accuracy_count['mor']/mor_valid_num\n",
    "        all_acc=(accuracy_count['sem']+accuracy_count['mor'])/all_valid_num\n",
    "        sem_cover=sem_valid_num/sem_num\n",
    "        mor_cover=mor_valid_num/mor_num\n",
    "        all_cover=all_valid_num/all_num\n",
    "        sem_accuracy.append(sem_acc)\n",
    "        mor_accuracy.append(mor_acc)\n",
    "        all_accuracy.append(all_acc)\n",
    "        sem_coverage.append(sem_cover)\n",
    "        mor_coverage.append(mor_cover)\n",
    "        all_coverage.append(all_cover)\n",
    "        print(f\"Analogy:模型{Round+1}/{len(vectors_list)}测试完成\")\n",
    "        Round+=1\n",
    "    model_info['analogy_sem']=sem_accuracy\n",
    "    model_info['analogy_sem_coverage']=sem_coverage\n",
    "    model_info['analogy_mor']=mor_accuracy\n",
    "    model_info['analogy_mor_coverage']=mor_coverage\n",
    "    model_info['analogy_all']=all_accuracy\n",
    "    model_info['analogy_all_coverage']=all_coverage\n",
    "    print('analogy测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ead79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试预训练模型词向量并保存结果\n",
    "def test_pretrained_models(vectors_list,modelnames):\n",
    "    model_info=pd.DataFrame(modelnames,columns=['model_name'])\n",
    "    wordsim_test(model_info,vectors_list,test_data_path='test_data/WordSim-353.csv')\n",
    "    simlex_test(model_info,vectors_list,test_data_path='test_data/SimLex-999.txt')\n",
    "    analogy_test(model_info,vectors_list,test_data_path='test_data/GoogleAnalogy.txt')\n",
    "    model_info.to_csv('pretrainedmodel_info.csv',encoding='utf-8',index=False)\n",
    "    print('结果已保存为pretrainedmodel_info.csv')\n",
    "    print(model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1031169",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('pretrained_models', exist_ok=True)\n",
    "word2vec_google_vectors=get_pretrained_vectors('word2vec-google-news-300')\n",
    "glove_wiki_vectors=get_pretrained_vectors('glove-wiki-gigaword-300')\n",
    "fasttext_wiki_vectors=get_pretrained_vectors('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1907b960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordsim测试完成\n",
      "simlex测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "analogy_test_sem: 100%|██████████| 8869/8869 [06:02<00:00, 24.47it/s] \n",
      "analogy_test_mor: 100%|██████████| 10675/10675 [16:26<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy:模型1/3测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "analogy_test_sem: 100%|██████████| 8869/8869 [02:00<00:00, 73.52it/s]\n",
      "analogy_test_mor: 100%|██████████| 10675/10675 [02:32<00:00, 70.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy:模型2/3测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "analogy_test_sem: 100%|██████████| 8869/8869 [02:56<00:00, 50.19it/s] \n",
      "analogy_test_mor: 100%|██████████| 10675/10675 [06:09<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy:模型3/3测试完成\n",
      "analogy测试完成\n",
      "结果已保存为pretrainedmodel_info.csv\n",
      "                        model_name  wordsim_r   wordsim_p_r  wordsim_rho  \\\n",
      "0         word2vec-google-news-300   0.649271  2.822799e-43     0.694122   \n",
      "1          glove-wiki-gigaword-300   0.604076  1.752305e-36     0.608535   \n",
      "2  fasttext-wiki-news-subwords-300   0.699496  3.687972e-53     0.697190   \n",
      "\n",
      "   wordsim_prho  wordsim_coverage  simlex_r    simlex_p_r  simlex_rho  \\\n",
      "0  1.287506e-51          0.991501  0.453928  6.173059e-52    0.441966   \n",
      "1  3.879630e-37          1.000000  0.388952  1.987671e-37    0.370500   \n",
      "2  1.115469e-52          1.000000  0.473067  7.587646e-57    0.440908   \n",
      "\n",
      "    simlex_prho  simlex_coverage  analogy_sem  analogy_sem_coverage  \\\n",
      "0  5.068222e-49              1.0     0.245799              0.416056   \n",
      "1  7.320031e-34              1.0     0.774383              1.000000   \n",
      "2  9.055669e-49              1.0     0.375822              0.582929   \n",
      "\n",
      "   analogy_mor  analogy_mor_coverage  analogy_all  analogy_all_coverage  \n",
      "0     0.658445              0.949508     0.548315              0.707429  \n",
      "1     0.669977              1.000000     0.717356              1.000000  \n",
      "2     0.874567              1.000000     0.711833              0.810735  \n"
     ]
    }
   ],
   "source": [
    "vectors_list=[word2vec_google_vectors,glove_wiki_vectors,fasttext_wiki_vectors]\n",
    "modelname_list=['word2vec-google-news-300','glove-wiki-gigaword-300','fasttext-wiki-news-subwords-300']\n",
    "test_pretrained_models(vectors_list=vectors_list,modelnames=modelname_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
