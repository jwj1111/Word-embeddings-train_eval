{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import scipy.stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从按参数保存的文件名中读取模型参数\n",
    "def read_model_infos(dir):\n",
    "    model_infos=[]\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith('.model'):\n",
    "            model_info={}\n",
    "            modelname=filename.split('.')[0]\n",
    "            params=modelname.split('_')\n",
    "            model_info['style']=params[0]\n",
    "            model_info['windows']=params[1].split('-')[-1]\n",
    "            model_info['vec_size']=params[2].split('-')[-1]\n",
    "            model_info['epochs']=params[3].split('-')[-1]\n",
    "            model_info['path']=f'''{dir}/{filename}'''\n",
    "            model_infos.append(model_info)\n",
    "    ModelInfo_df=pd.DataFrame(model_infos)\n",
    "    return ModelInfo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入测试数据并统一输出格式\n",
    "def test_data_prepare(filename):\n",
    "    with open(filename,'r',encoding='utf-8') as infile:\n",
    "        if 'WordSim' in filename: #针对wordsim\n",
    "            pair_gold=[]\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if not line.startswith('Word 1'):\n",
    "                    line_elements=line.split(',')\n",
    "                    pair_gold.append(((line_elements[0].lower(),line_elements[1].lower()),float(line_elements[2])))\n",
    "            return pair_gold\n",
    "        if 'SimLex' in filename: #针对simlex\n",
    "            pair_gold=[]\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if not line.startswith('word1'):\n",
    "                    line_elements=line.split('\\t')\n",
    "                    pair_gold.append(((line_elements[0].lower(),line_elements[1].lower()),float(line_elements[3])))\n",
    "            return pair_gold\n",
    "        if 'Analogy' in filename: #针对google analogy\n",
    "            sem_positives_negative=[]\n",
    "            sem_answers=[]\n",
    "            mor_positives_negative=[]\n",
    "            mor_answers=[]\n",
    "            category=None\n",
    "            for line in infile:\n",
    "                line=line.strip()\n",
    "                if line.startswith(':'):\n",
    "                    category=1 if 'gram' in line else 0\n",
    "                else:\n",
    "                    line_elements=line.split()\n",
    "                    if category==0:\n",
    "                        sem_positives_negative.append(([line_elements[2].lower(),line_elements[1].lower()],line_elements[0].lower()))\n",
    "                        sem_answers.append(line_elements[3].lower())\n",
    "                    else:\n",
    "                        mor_positives_negative.append(([line_elements[2].lower(),line_elements[1].lower()],line_elements[0].lower()))\n",
    "                        mor_answers.append(line_elements[3].lower())        \n",
    "            return sem_positives_negative,sem_answers,mor_positives_negative,mor_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试相似性判断能力\n",
    "def similarity_test(pair_gold,model_paths):\n",
    "    r_values=[]\n",
    "    p_r_values=[]\n",
    "    rho_values=[]\n",
    "    p_rho_values=[]\n",
    "    test_coverage=[] #因oov，设置了覆盖率的统计\n",
    "    test_pair_num=len(pair_gold)\n",
    "    for filepath in model_paths:\n",
    "        test_model=Word2Vec.load(filepath)\n",
    "        test_vectors=test_model.wv\n",
    "        gold_sim=[]\n",
    "        pred_sim=[]\n",
    "        oov_pair_num=0\n",
    "        for pair,gold in pair_gold:\n",
    "            try:\n",
    "                pred=test_vectors.similarity(*pair)\n",
    "                gold_sim.append(gold)\n",
    "                pred_sim.append(pred)\n",
    "            except KeyError: #oov不纳入测试范围\n",
    "                oov_pair_num+=1\n",
    "                continue\n",
    "        r,p_r=scipy.stats.pearsonr(gold_sim,pred_sim)\n",
    "        rho,p_rho=scipy.stats.spearmanr(gold_sim,pred_sim)\n",
    "        coverage=(test_pair_num-oov_pair_num)/test_pair_num\n",
    "        r_values.append(r)\n",
    "        p_r_values.append(p_r)\n",
    "        rho_values.append(rho)\n",
    "        p_rho_values.append(p_rho)\n",
    "        test_coverage.append(coverage)\n",
    "    return r_values,p_r_values,rho_values,p_rho_values,test_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsim_test(model_info_dataframe,data_path):\n",
    "    wordsim_pair_gold=test_data_prepare(data_path)\n",
    "    wordsim_r,wordsim_pr,wordsim_rho,wordsim_prho,wordsim_coverage=similarity_test(pair_gold=wordsim_pair_gold,model_paths=model_info_dataframe['path'])\n",
    "    model_info_dataframe['wordsim_r']=wordsim_r\n",
    "    model_info_dataframe['wordsim_p_r']=wordsim_pr\n",
    "    model_info_dataframe['wordsim_rho']=wordsim_rho\n",
    "    model_info_dataframe['wordsim_prho']=wordsim_prho\n",
    "    model_info_dataframe['wordsim_coverage']=wordsim_coverage\n",
    "    print('wordsim测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simlex_test(model_info_dataframe,data_path):\n",
    "    simlex_pair_gold=test_data_prepare(data_path)\n",
    "    simlex_r,simlex_pr,simlex_rho,simlex_prho,simlex_coverage=similarity_test(pair_gold=simlex_pair_gold,model_paths=model_info_dataframe['path'])\n",
    "    model_info_dataframe['simlex_r']=simlex_r\n",
    "    model_info_dataframe['simlex_p_r']=simlex_pr\n",
    "    model_info_dataframe['simlex_rho']=simlex_rho\n",
    "    model_info_dataframe['simlex_prho']=simlex_prho\n",
    "    model_info_dataframe['simlex_coverage']=simlex_coverage\n",
    "    print('simlex测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试类比推理的能力\n",
    "def analogy_test(model_info_dataframe,data_path):\n",
    "    sem_positives_negative,sem_answers,mor_positives_negative,mor_answers=test_data_prepare(data_path)\n",
    "    model_paths=model_info_dataframe['path']\n",
    "    sem_num,mor_num=len(sem_positives_negative),len(mor_positives_negative)\n",
    "    all_num=sem_num+mor_num\n",
    "    sem_accuracy,mor_accuracy,all_accuracy=[],[],[]\n",
    "    sem_coverage,mor_coverage,all_coverage=[],[],[] #因oov设置覆盖率统计\n",
    "    Round=0\n",
    "    for filepath in model_paths:\n",
    "        accuracy_count={'sem':0,'mor':0}\n",
    "        test_model=Word2Vec.load(filepath)\n",
    "        test_vectors=test_model.wv\n",
    "        sem_oov_pair_num=0 #oov设置\n",
    "        mor_oov_pair_num=0 #oov设置\n",
    "        for sem_pos_neg,sem_answer in zip(sem_positives_negative,sem_answers):\n",
    "            sem_pos_pair,sem_neg=sem_pos_neg\n",
    "            try:\n",
    "                pred_semword=test_vectors.most_similar(positive=sem_pos_pair,negative=[sem_neg],topn=1)[0][0]\n",
    "                if pred_semword==sem_answer:\n",
    "                    accuracy_count['sem']+=1\n",
    "            except KeyError: #oov不纳入\n",
    "                sem_oov_pair_num+=1\n",
    "                continue\n",
    "        for mor_pos_neg,mor_answer in zip(mor_positives_negative,mor_answers):\n",
    "            mor_pos_pair,mor_neg=mor_pos_neg\n",
    "            try:\n",
    "                pred_morword=test_vectors.most_similar(positive=mor_pos_pair,negative=[mor_neg],topn=1)[0][0]\n",
    "                if pred_morword==mor_answer:\n",
    "                    accuracy_count['mor']+=1\n",
    "            except KeyError: #oov不纳入\n",
    "                mor_oov_pair_num+=1\n",
    "                continue\n",
    "        sem_valid_num=sem_num-sem_oov_pair_num\n",
    "        mor_valid_num=mor_num-mor_oov_pair_num\n",
    "        all_valid_num=all_num-sem_oov_pair_num-mor_oov_pair_num\n",
    "        sem_acc=accuracy_count['sem']/sem_valid_num\n",
    "        mor_acc=accuracy_count['mor']/mor_valid_num\n",
    "        all_acc=(accuracy_count['sem']+accuracy_count['mor'])/all_valid_num\n",
    "        sem_cover=sem_valid_num/sem_num\n",
    "        mor_cover=mor_valid_num/mor_num\n",
    "        all_cover=all_valid_num/all_num\n",
    "        sem_accuracy.append(sem_acc)\n",
    "        mor_accuracy.append(mor_acc)\n",
    "        all_accuracy.append(all_acc)\n",
    "        sem_coverage.append(sem_cover)\n",
    "        mor_coverage.append(mor_cover)\n",
    "        all_coverage.append(all_cover)\n",
    "        print(f\"Analogy:模型{Round+1}/{len(model_paths)}测试完成\")\n",
    "        Round+=1\n",
    "    model_info_dataframe['analogy_sem']=sem_accuracy\n",
    "    model_info_dataframe['analogy_sem_coverage']=sem_coverage\n",
    "    model_info_dataframe['analogy_mor']=mor_accuracy\n",
    "    model_info_dataframe['analogy_mor_coverage']=mor_coverage\n",
    "    model_info_dataframe['analogy_all']=all_accuracy\n",
    "    model_info_dataframe['analogy_all_coverage']=all_coverage\n",
    "    print('analogy测试完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因similarity和analogy结果差异大\n",
    "#在similarity测试规则下得到最佳模型（wordsim和simlex在（rho和r，rho优先）都要前15，筛选后按simlex rho，simlex r，wordsim rho，wordsim r排序（simlex优先）得到最佳模型）\n",
    "def get_best_similarity(model_info_dataframe,top_num):\n",
    "    result_sorted_wordsim=model_info_dataframe[(model_info_dataframe['wordsim_p_r']<0.05)&(model_info_dataframe['wordsim_prho']<0.05)].sort_values(by=['wordsim_rho','wordsim_r'],ascending=False).head(top_num)\n",
    "    result_sorted_simlex=model_info_dataframe[(model_info_dataframe['simlex_p_r']<0.05)&(model_info_dataframe['simlex_prho']<0.05)].sort_values(by=['simlex_rho','simlex_r'],ascending=False).head(top_num)\n",
    "    wordsim_indices=set(result_sorted_wordsim['index'])\n",
    "    simlex_indices=set(result_sorted_simlex['index'])\n",
    "    indices=list(simlex_indices&wordsim_indices)\n",
    "    result_wordsim_simlex=model_info_dataframe.loc[indices]\n",
    "    result_sorted_similarity=result_wordsim_simlex.sort_values(by=['simlex_rho','simlex_r','wordsim_rho','wordsim_r'],ascending=False).head(1)\n",
    "    return result_sorted_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因similarity和analogy结果差异大\n",
    "#在analogy测试规则下得到最佳模型（all_accuracy优先）\n",
    "def get_best_analogy(model_info_dataframe):\n",
    "    result_sorted_analogy=model_info_dataframe.sort_values(by='analogy_all',ascending=False).head(1)\n",
    "    return result_sorted_analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取并保存最佳模型\n",
    "def get_best_models(model_info_dataframe,top_num_for_similarity):\n",
    "    best_similarity_model_info=get_best_similarity(model_info_dataframe,top_num_for_similarity)\n",
    "    best_analogy_model_info=get_best_analogy(model_info_dataframe)\n",
    "    best_models_df=pd.concat([best_similarity_model_info,best_analogy_model_info],axis=0)\n",
    "    best_models_df.to_csv('bestmodels_info.csv',encoding='utf-8',index=False)\n",
    "    print('最佳模型信息已保存至bestmodels_info.csv')\n",
    "    return best_models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 1/3 [00:09<00:19,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordsim测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 2/3 [00:19<00:09,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simlex测试完成\n",
      "Analogy:模型1/36测试完成\n",
      "Analogy:模型2/36测试完成\n",
      "Analogy:模型3/36测试完成\n",
      "Analogy:模型4/36测试完成\n",
      "Analogy:模型5/36测试完成\n",
      "Analogy:模型6/36测试完成\n",
      "Analogy:模型7/36测试完成\n",
      "Analogy:模型8/36测试完成\n",
      "Analogy:模型9/36测试完成\n",
      "Analogy:模型10/36测试完成\n",
      "Analogy:模型11/36测试完成\n",
      "Analogy:模型12/36测试完成\n",
      "Analogy:模型13/36测试完成\n",
      "Analogy:模型14/36测试完成\n",
      "Analogy:模型15/36测试完成\n",
      "Analogy:模型16/36测试完成\n",
      "Analogy:模型17/36测试完成\n",
      "Analogy:模型18/36测试完成\n",
      "Analogy:模型19/36测试完成\n",
      "Analogy:模型20/36测试完成\n",
      "Analogy:模型21/36测试完成\n",
      "Analogy:模型22/36测试完成\n",
      "Analogy:模型23/36测试完成\n",
      "Analogy:模型24/36测试完成\n",
      "Analogy:模型25/36测试完成\n",
      "Analogy:模型26/36测试完成\n",
      "Analogy:模型27/36测试完成\n",
      "Analogy:模型28/36测试完成\n",
      "Analogy:模型29/36测试完成\n",
      "Analogy:模型30/36测试完成\n",
      "Analogy:模型31/36测试完成\n",
      "Analogy:模型32/36测试完成\n",
      "Analogy:模型33/36测试完成\n",
      "Analogy:模型34/36测试完成\n",
      "Analogy:模型35/36测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 3/3 [12:13<00:00, 244.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy:模型36/36测试完成\n",
      "analogy测试完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ModelInfo_df=read_model_infos('models')\n",
    "with tqdm(total=3,desc='Testing') as pbar:\n",
    "    wordsim_test(model_info_dataframe=ModelInfo_df,data_path='test_data/WordSim-353.csv')\n",
    "    pbar.update(1)\n",
    "    simlex_test(model_info_dataframe=ModelInfo_df,data_path='test_data/SimLex-999.txt')\n",
    "    pbar.update(1)\n",
    "    analogy_test(model_info_dataframe=ModelInfo_df,data_path='test_data/GoogleAnalogy.txt')\n",
    "    pbar.update(1)\n",
    "ModelInfo_df=ModelInfo_df.reset_index()\n",
    "ModelInfo_df.to_csv('allmodel_info.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型信息已保存至bestmodels_info.csv\n"
     ]
    }
   ],
   "source": [
    "best_models_df=get_best_models(model_info_dataframe=ModelInfo_df,top_num_for_similarity=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
