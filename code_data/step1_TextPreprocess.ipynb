{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10414595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "puncts=set('…。！＂＃＄％＆＇（）＊＋，－．／：；＜＝＞？＠［＼］＾＿｀｛｜｝～'+string.punctuation) #对spacy默认punct判别的补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentence(filename): #定义生成器按句载入语料，便于控制资源占用和训练语料规模\n",
    "    with open(filename,'r',encoding='utf-8') as infile:\n",
    "        for line in infile:\n",
    "            yield line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78469007",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token_num=30000000 #仅处理三千万tokens的语料\n",
    "sents_processed=[]\n",
    "num=0\n",
    "pbar=tqdm(total=target_token_num,desc='处理tokens')\n",
    "for sent in read_sentence(r'text_raw/en.txt'):\n",
    "    if num>=target_token_num:\n",
    "        break\n",
    "    sent_tokens=[]\n",
    "    sent_nlp=nlp(sent)\n",
    "    for token in sent_nlp:\n",
    "        if num>=target_token_num:\n",
    "            pbar.close()\n",
    "            break\n",
    "        if not (token.is_punct or token.is_space or (token.text in puncts)):\n",
    "            sent_tokens.append(token.text.lower())\n",
    "            num+=1\n",
    "            pbar.update(1)\n",
    "    sent_processed=' '.join(sent_tokens)\n",
    "    sents_processed.append(sent_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('text_processed',exist_ok=True)\n",
    "with open(r'text_processed/en_processed.txt','w',encoding='utf-8') as outfile:\n",
    "    for sentence in sents_processed:\n",
    "        outfile.write(sentence+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
